{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d3e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import re\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15403610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyc_opentable_scraper(borough, date, starting_page):\n",
    "    \"\"\"\n",
    "    nyc_opentable_scraper: given a borough and date, scrapes the OpenTable search results front page to see how many pages of\n",
    "    results there are for that borough and date. Calls get_restaurants() on each of those results pages, and writes\n",
    "    the information scraped from each restaurant to a line in a csv file by calling restaurants_to_csv()\n",
    "    \n",
    "    args:\n",
    "        borough: string, one of 'manhattan', 'brooklyn', 'bronx', 'queens', or 'staten_island'\n",
    "        date: string in format 'YYYY-mm-dd'\n",
    "            WARNING: passing a date earlier than the current date will not provide correct information\n",
    "        starting_page: int, the number of the search results pages to start scraping from\n",
    "            Usually 1. Mostly implemented to pick up where it left off during debugging if there was an error\n",
    "    \n",
    "    output:\n",
    "        Creates a csv file named <date>_<borough>_page<i> for each page of search results for input borough and date\n",
    "    \n",
    "    \"\"\"\n",
    "    i = starting_page\n",
    "    frontpages = {\n",
    "    'manhattan' : f'https://www.opentable.com/s?dateTime={date}T20%3A00%3A00&covers=1&metroId=8&regionIds%5B%5D=16&term=&corrid=d0436a58-4f45-4c4f-9992-e70b98b5157f&sortBy=newest_arrivals&queryUnderstandingType=none&page={i}',\n",
    "    'brooklyn' : f'https://www.opentable.com/s?dateTime={date}T20%3A00%3A00&covers=1&metroId=8&regionIds%5B%5D=24&term=&corrid=d12a66c7-6561-4119-8bd9-8ddfb2719cca&sortBy=newest_arrivals&queryUnderstandingType=none&page={i}',\n",
    "    'queens' : f'https://www.opentable.com/s?dateTime={date}T20%3A00%3A00&covers=1&metroId=8&regionIds%5B%5D=17&term=&corrid=b58c0eae-160f-4ef7-90d7-c228211fe416&sortBy=newest_arrivals&queryUnderstandingType=none&page={i}',\n",
    "    'bronx' : f'https://www.opentable.com/s?dateTime={date}-20T20%3A00%3A00&covers=1&metroId=8&regionIds%5B%5D=324&term=&corrid=b58c0eae-160f-4ef7-90d7-c228211fe416&sortBy=newest_arrivals&queryUnderstandingType=none&page={i}',\n",
    "    'staten_island' :  f'https://www.opentable.com/s?dateTime={date}T20%3A00%3A00&covers=1&metroId=8&regionIds%5B%5D=18&term=&corrid=b58c0eae-160f-4ef7-90d7-c228211fe416&sortBy=newest_arrivals&queryUnderstandingType=none&page={i}'   \n",
    "    }\n",
    "    \n",
    "    if borough not in frontpages:\n",
    "        raise ValueError(\"The 5 boroughs are 'manhattan', 'brooklyn', 'bronx', 'queens', and 'staten_island'\")\n",
    "    \n",
    "    results_frontpage = frontpages[borough]\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get(results_frontpage)\n",
    "    frontpage_html = driver.page_source\n",
    "    time.sleep(0.1)\n",
    "    driver.close()\n",
    "    \n",
    "    frontpage_soup = soup(frontpage_html, 'html.parser')\n",
    "    total_restaurants = int(re.search('\\d+', frontpage_soup.find('h3', attrs = {\"class\" : \"_6X5n-Vu8eAbxx_nrEuxjc\", \"data-test\" : \"multi-search-total-count\"}).string).group(0))\n",
    "    print(total_restaurants)\n",
    "    if total_restaurants % 100 == 0:\n",
    "        num_results_pages = (total_restaurants/100)\n",
    "    else:\n",
    "        num_results_pages = int((total_restaurants/100) + 1)\n",
    "    \n",
    "    print(f'Total results pages: {num_results_pages}')\n",
    "          \n",
    "    rest_keys = ['name', 'url', 'is_member', 'promoted', 'price_tier', 'review_count', 'overall', 'food', 'service', 'ambience', 'value',\n",
    "       'noise', 'pct_recommended', 'neighborhood', 'cuisines', 'dining_style', 'dress_code', 'chef', 'tags',\n",
    "       'primary_cuisine', 'sanitizing', 'distancing', 'ppe', 'screening']\n",
    "    i = 1\n",
    "    while i <= num_results_pages:\n",
    "        page_i = frontpages[borough]\n",
    "        print(page_i)\n",
    "        page_i_rest_list = get_restaurants(page_i)\n",
    "        restaurants_to_csv(page_i_rest_list, f'{date}_{borough}_page{i}.csv', rest_keys)\n",
    "        print()\n",
    "        print(f'exported page {i}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb5d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurants(results_url):\n",
    "    \"\"\"\n",
    "    get_restaurants: gets names, urls, and promoted status of all restaurant pages on a given search results page\n",
    "        Calls get_restaurant_info() on each of the urls found.\n",
    "    \n",
    "    args:\n",
    "        results_url: the url of the search results page to scrape\n",
    "        \n",
    "    output:\n",
    "        rest_list: a list of dictionaries, each containing the information from one restaurant, scraped both by\n",
    "        this function and by get_restaurant_info()\n",
    "    \"\"\"\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get(results_url)\n",
    "\n",
    "    # scroll down page incrementally to load restaurant elements\n",
    "    y = 500\n",
    "    for timer in range(0,70):\n",
    "        driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "        y += 500\n",
    "        time.sleep(0.05)\n",
    "    results_html = driver.page_source\n",
    "    time.sleep(0.1)\n",
    "    driver.close()\n",
    "    \n",
    "    \n",
    "    results = soup(results_html, 'html.parser')\n",
    "    restaurants = results.find_all('div', attrs = {\"class\" : \"_3uVfVbI1iLfMbszbU6KoOL\"})\n",
    "    print(f'{len(restaurants)} restaurants on results page {results_url} found')\n",
    "    \n",
    "    rest_list = [None]*len(restaurants)\n",
    "    \n",
    "    rest_keys = ['name', 'url', 'is_member', 'promoted', 'price_tier', 'review_count', 'overall', 'food', 'service', 'ambience', 'value',\n",
    "       'noise', 'pct_recommended', 'neighborhood', 'cuisines', 'dining_style', 'dress_code', 'chef', 'tags',\n",
    "       'primary_cuisine', 'sanitizing', 'distancing', 'ppe', 'screening']\n",
    "    \n",
    "    i = 0\n",
    "    for restaurant in restaurants:\n",
    "        \n",
    "        # initialize all keys to None\n",
    "        curr_rest_dict = dict(zip(rest_keys, [None]*len(rest_keys)))\n",
    "        \n",
    "        # get restaurant name\n",
    "        restaurant_child = restaurant.find('a', attrs = {\"class\":\"_1e9PcCDb012hY4BcGfraQB\"})\n",
    "        curr_rest_dict['name'] = restaurant_child.get('aria-label')\n",
    "\n",
    "        # get restaurant url\n",
    "        rest_url = restaurant_child.get('href')\n",
    "        curr_rest_dict['url'] = rest_url\n",
    "        \n",
    "        # check whether restaurant is on opentable's reservation service. If not, there will be no details on restaurant page and we can skip\n",
    "        curr_rest_dict['is_member'] = 0 if restaurant.find('p', attrs = {\"class\":\"_1RzTbFM0hmdDgWfT_RmXel\"}) else 1\n",
    "\n",
    "        if curr_rest_dict['is_member'] == 1:\n",
    "\n",
    "            # get promoted status\n",
    "            curr_rest_dict['promoted'] = 1 if restaurant.get('data-promoted') == 'true' else 0\n",
    "\n",
    "            get_restaurant_info(curr_rest_dict['url'], curr_rest_dict)\n",
    "\n",
    "        print(curr_rest_dict['name'], end = ', ')\n",
    "        rest_list[i] = curr_rest_dict\n",
    "        i+=1\n",
    "         \n",
    "    return rest_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6221efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_info(url, curr_rest_dict):\n",
    "    \"\"\"\n",
    "    get_restaurant_info: extracts information from restaurant pages whose urls were found by get_restaurants()\n",
    "    \n",
    "    args:\n",
    "        url: url of the restaurant page\n",
    "        curr_rest_dict: the dict of information on each restaurant generated by get_restaurants()\n",
    "    \n",
    "    output:\n",
    "        no return, mutating function\n",
    "        navigates the restaurant page and adds the following keys and values to curr_rest_dict:\n",
    "            \n",
    "            review_count: int, total # of reviews received\n",
    "            ----------------------------------------------------------------------------\n",
    "            \n",
    "            RATINGS- all rating values are floats, out of 5.0 maximum rating\n",
    "            -----------------------------------------------------------------------------\n",
    "            overall: overall average rating by reviewers\n",
    "            food: average food rating by reviewers\n",
    "            service: average service rating by reviewers\n",
    "            ambience: average ambience rating by reviewers\n",
    "            value: average value rating by reviewers\n",
    "            -----------------------------------------------------------------------------\n",
    "            \n",
    "            noise: string, noise level. Quiet, Moderate, or Energetic.\n",
    "            pct_recommended: int, percent of reviewers who would recommend restaurant to a friend\n",
    "            -----------------------------------------------------------------------------\n",
    "            \n",
    "            DETAILS- all details values are strings, with None if key not found on page\n",
    "            -----------------------------------------------------------------------------\n",
    "            neighborhood: neighborhood in which restaurant is located\n",
    "            hours: hours of operation\n",
    "            cuisines: cuisine styles served\n",
    "            dining_style: dining style (fine dining, casual, etc)\n",
    "            dress_code: dress code\n",
    "            chef: chef's name\n",
    "            tags: additional tags\n",
    "            primary_cuisine: first item in cuisines, as listed on results page\n",
    "            -----------------------------------------------------------------------------\n",
    "            \n",
    "            COVID-19 MEASURES- all values are bool, 1 if safety measure is implemented, 0 if not\n",
    "            -----------------------------------------------------------------------------\n",
    "            sanitizing: sanitization or enhanced cleaning practices\n",
    "            distancing: physical distancing, barriers between tables, etc\n",
    "            ppe: (personal protective equipment) mask-wearing by staff and requiring customers to do so\n",
    "            screening: customer temperature checking, contact tracing\n",
    "        \n",
    "    \"\"\"\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    driver.maximize_window() # maximize to make sure page sidebar is loaded\n",
    "    rest_html = driver.page_source\n",
    "    driver.close()\n",
    "\n",
    "    curr_rest = soup(rest_html, 'html.parser')\n",
    "    \n",
    "    # get number of reviews, price range\n",
    "    divs = curr_rest.find_all('div', attrs = {\"class\" : \"c3981cf8 _965a91d5\"})\n",
    "    for div in divs:\n",
    "        spans = div.find_all('span')\n",
    "        for span in spans:\n",
    "            if \"Reviews\" in span.string:\n",
    "                curr_rest_dict['review_count'] = span.string\n",
    "            if \"$\" in span.string:\n",
    "                curr_rest_dict['price_tier'] = span.string\n",
    "                \n",
    "    has_reviews = 1 \n",
    "    if curr_rest_dict['review_count'] == \"No Reviews\":\n",
    "        has_reviews = 0\n",
    "    \n",
    "    # get overall rating and subratings\n",
    "    if has_reviews:\n",
    "        curr_rest_dict['overall'] = float(curr_rest.find('div', attrs = {\"class\" : \"oc-reviews-491257d8\"}).span.string)\n",
    "        subreviews = curr_rest.find_all('div', attrs = {\"class\" : \"oc-reviews-15d38b07\"})\n",
    "        if subreviews != []:\n",
    "            curr_rest_dict['food'] = float(subreviews[0].string)\n",
    "            curr_rest_dict['service'] = float(subreviews[1].string)\n",
    "            curr_rest_dict['ambience'] = float(subreviews[2].string)\n",
    "            curr_rest_dict['value'] = float(subreviews[3].string)\n",
    "\n",
    "    # get noise level\n",
    "    noise_level = curr_rest.find('span', attrs = {\"class\" : \"oc-reviews-624ebf8b\"})\n",
    "    if not (noise_level is None):\n",
    "        curr_rest_dict['noise'] = noise_level.string\n",
    "    \n",
    "\n",
    "    # get percent of reviewers who would recommended to a friend\n",
    "    if has_reviews:\n",
    "        recs_parent = curr_rest.find_all('div', attrs = {\"class\" : \"oc-reviews-8c8e52a0\"})\n",
    "        has_recs = 0\n",
    "        for div in recs_parent:\n",
    "            spans = div.find_all('span', attrs = {\"class\" : \"oc-reviews-624ebf8b\"})\n",
    "            for span in spans:\n",
    "                if span.string == 'would recommend it to a friend':\n",
    "                    has_recs = 1\n",
    "        \n",
    "        if has_recs == 1:\n",
    "            recs = curr_rest.find_all('div', attrs = {\"class\" : \"oc-reviews-dfc07aec\"})[1]\n",
    "            recs_2 = re.search('\\d+%', recs.get_text())\n",
    "            if not (recs_2 is None):\n",
    "                rec_string = recs_2.group(0)\n",
    "                curr_rest_dict['pct_recommended'] = int(re.search('\\d+', rec_string).group(0))\n",
    "\n",
    "    details_tags = ['neighborhood', 'cuisines', 'dining_style', 'dress_code', 'chef', 'tags']\n",
    "\n",
    "    # zip (field, value) tuples of restaurant page sidebar information into details_list\n",
    "    sidebar = curr_rest.find('div', attrs = {\"class\":\"_1e466fbf\"})\n",
    "    if not(sidebar is None):\n",
    "        details = sidebar.find_all('div', attrs = {\"class\":\"df8add00\"})\n",
    "        details_list = [zip(item.find_all('div', attrs = {\"class\":\"c3981cf8 _965a91d5\"}), \n",
    "                            item.find_all('div', attrs = {\"class\":\"e7ff71b6 b2f6d1a4\"})) for item in details] \n",
    "        for i in range(len(details_list)):\n",
    "            for x, y in details_list[i]:\n",
    "                details_list[i] = (x.string, y.string)\n",
    "\n",
    "        # filter details_list for desired information, add info to curr_rest_dict\n",
    "        desired_details = zip(['Neighborhood', 'Cuisines', 'Dining Style', 'Dress code', '(?i)(.*chef.*)', 'Additional'], details_tags)\n",
    "\n",
    "        for x, y in desired_details:\n",
    "            for a, b in details_list:\n",
    "                if re.search(x, a):\n",
    "                    curr_rest_dict[y] = b\n",
    "    \n",
    "    # gets first tag in cuisines as primary cuisine\n",
    "    if not (curr_rest_dict['cuisines'] is None):\n",
    "        curr_rest_dict['primary_cuisine'] = curr_rest_dict['cuisines'].split(',')[0]\n",
    "    \n",
    "    # check whether restaurant has safety information element at all\n",
    "    if not (curr_rest.find('div', attrs = {\"id\" : \"safety-precautions\"}) is None):\n",
    "        \n",
    "        safety_categories = ['Cleaning & Sanitizing', 'Physical Distancing', 'Protective Equipment','Screening']\n",
    "        safety_tags = ['sanitizing', 'distancing', 'ppe', 'screening']\n",
    "        \n",
    "        # set keys for safety information to 0\n",
    "        for item in safety_tags:\n",
    "            curr_rest_dict[item] = 0\n",
    "\n",
    "\n",
    "        # get COVID-19 safety information\n",
    "        safety_html = curr_rest.find_all('div', attrs = {\"class\" : \"_77b505d0 _965a91d5\"})\n",
    "        safety_features = [item.find('span').string for item in safety_html]\n",
    "\n",
    "        for i in range(len(safety_categories)):\n",
    "            for j in range(len(safety_features)):\n",
    "                if safety_categories[i] == safety_features[j]:\n",
    "                    curr_rest_dict[safety_tags[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e66cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurants_to_csv(rest_list, filename, headings_list):\n",
    "    \"\"\"\n",
    "    writes information scraped by other functions to csv file\n",
    "    \n",
    "    Args: \n",
    "        rest_list: the list of dictionaries of restaurant information created by get_restaurants()\n",
    "        filename: string, the name of the output csv file\n",
    "        headings_list: list containing column names for the csv file\n",
    "        \n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding = 'utf-8', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headings_list)\n",
    "\n",
    "        for rest_dict in rest_list:\n",
    "            csv_writer.writerow(rest_dict.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
